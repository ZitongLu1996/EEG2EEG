{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54cc5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import warnings\n",
    "import copy\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b08a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subid1 in range(10):\n",
    "    for subid2 in range(10):\n",
    "        if subid1 != subid2:\n",
    "            path = f'weights_steps/Sub{subid1+1}ToSub{subid2+1}_AllChannels'\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b539841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(condition, fake, real):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    condition = condition.detach().cpu().numpy()\n",
    "    fake = fake.detach().cpu().numpy()\n",
    "    real = real.detach().cpu().numpy()\n",
    "    t = np.arange(0, 200, 1)\n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "    axs[0].plot(t, condition[0, 0])\n",
    "    \n",
    "    axs[1].plot(t, real[0, 0], label='real')\n",
    "    axs[1].plot(t, fake[0, 0], label='fake')\n",
    "    axs[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8927a850",
   "metadata": {},
   "source": [
    "2D U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb6b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(data, new_shape):\n",
    "    '''\n",
    "    Function for cropping an image tensor: Given an image tensor and the new shape,\n",
    "    crops to the center pixels.\n",
    "    Parameters:\n",
    "        image: image tensor of shape (batch size, channels, height, width)\n",
    "        new_shape: a torch.Size object with the shape you want x to have\n",
    "    '''\n",
    "    middle_length = data.shape[2] // 2\n",
    "    starting = middle_length - round(new_shape[2] / 2)\n",
    "    final = starting + new_shape[2]\n",
    "    cropped_data = data[:, :, starting:final]\n",
    "    return cropped_data\n",
    "\n",
    "class ContractingBlock(nn.Module):\n",
    "    '''\n",
    "    ContractingBlock Class\n",
    "    Performs two convolutions followed by a max pool operation.\n",
    "    Values:\n",
    "        input_channels: the number of channels to expect from a given input\n",
    "    '''\n",
    "    def __init__(self, input_channels, use_dropout=False, use_bn=True):\n",
    "        super(ContractingBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, input_channels * 2, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(input_channels * 2, input_channels * 2, kernel_size=3, padding=1)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        if use_bn:\n",
    "            self.batchnorm = nn.BatchNorm1d(input_channels * 2)\n",
    "        self.use_bn = use_bn\n",
    "        if use_dropout:\n",
    "            self.dropout = nn.Dropout()\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Function for completing a forward pass of ContractingBlock: \n",
    "        Given an image tensor, completes a contracting block and returns the transformed tensor.\n",
    "        Parameters:\n",
    "            x: image tensor of shape (batch size, channels, height, width)\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class ExpandingBlock(nn.Module):\n",
    "    '''\n",
    "    ExpandingBlock Class:\n",
    "    Performs an upsampling, a convolution, a concatenation of its two inputs,\n",
    "    followed by two more convolutions with optional dropout\n",
    "    Values:\n",
    "        input_channels: the number of channels to expect from a given input\n",
    "    '''\n",
    "    def __init__(self, input_channels, use_dropout=False, use_bn=True):\n",
    "        super(ExpandingBlock, self).__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.conv1 = nn.Conv1d(input_channels, input_channels // 2, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(input_channels // 2, input_channels // 2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(input_channels // 2, input_channels // 2, kernel_size=3, padding=1)\n",
    "        if use_bn:\n",
    "            self.batchnorm = nn.BatchNorm1d(input_channels // 2)\n",
    "        self.use_bn = use_bn\n",
    "        self.activation = nn.ReLU()\n",
    "        if use_dropout:\n",
    "            self.dropout = nn.Dropout()\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Function for completing a forward pass of ExpandingBlock: \n",
    "        Given an image tensor, completes an expanding block and returns the transformed tensor.\n",
    "        Parameters:\n",
    "            x: image tensor of shape (batch size, channels, height, width)\n",
    "            skip_con_x: the image tensor from the contracting path (from the opposing block of x)\n",
    "                    for the skip connection\n",
    "        '''\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv3(x)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FeatureMapBlock0(nn.Module):\n",
    "    '''\n",
    "    FeatureMapBlock Class\n",
    "    The first layers of a U-Net - \n",
    "    maps each pixel to a pixel with the correct number of output dimensions\n",
    "    using a 1x1 convolution.\n",
    "    Values:\n",
    "        input_channels: the number of channels to expect from a given input\n",
    "        output_channels: the number of channels to expect for a given output\n",
    "    '''\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(FeatureMapBlock0, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, output_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(output_channels, output_channels, kernel_size=3, padding=1)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        self.batchnorm = nn.BatchNorm1d(output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Function for completing a forward pass of FeatureMapBlock: \n",
    "        Given an image tensor, returns it mapped to the desired number of channels.\n",
    "        Parameters:\n",
    "            x: image tensor of shape (batch size, channels, height, width)\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.activation(x)\n",
    "        return x   \n",
    "    \n",
    "class FeatureMapBlock(nn.Module):\n",
    "    '''\n",
    "    FeatureMapBlock Class\n",
    "    The final layer of a U-Net - \n",
    "    maps each pixel to a pixel with the correct number of output dimensions\n",
    "    using a 1x1 convolution.\n",
    "    Values:\n",
    "        input_channels: the number of channels to expect from a given input\n",
    "        output_channels: the number of channels to expect for a given output\n",
    "    '''\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(FeatureMapBlock, self).__init__()\n",
    "        self.conv = nn.Conv1d(input_channels, output_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Function for completing a forward pass of FeatureMapBlock: \n",
    "        Given an image tensor, returns it mapped to the desired number of channels.\n",
    "        Parameters:\n",
    "            x: image tensor of shape (batch size, channels, height, width)\n",
    "        '''\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    '''\n",
    "    UNet Class\n",
    "    A series of 4 contracting blocks followed by 4 expanding blocks to \n",
    "    transform an input image into the corresponding paired image, with an upfeature\n",
    "    layer at the start and a downfeature layer at the end.\n",
    "    Values:\n",
    "        input_channels: the number of channels to expect from a given input\n",
    "        output_channels: the number of channels to expect for a given output\n",
    "    '''\n",
    "    def __init__(self, input_channels, output_channels, hidden_channels=64):\n",
    "        super(UNet, self).__init__()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.contract1 = FeatureMapBlock0(input_channels, hidden_channels)\n",
    "        self.contract2 = ContractingBlock(hidden_channels, use_dropout=True)\n",
    "        self.contract3 = ContractingBlock(hidden_channels * 2, use_dropout=True)\n",
    "        self.contract4 = ContractingBlock(hidden_channels * 4)\n",
    "        self.expand1 = ExpandingBlock(hidden_channels * 8)\n",
    "        self.expand2 = ExpandingBlock(hidden_channels * 4)\n",
    "        self.expand3 = ExpandingBlock(hidden_channels * 2)\n",
    "        self.downfeature = FeatureMapBlock(hidden_channels, output_channels)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Function for completing a forward pass of UNet: \n",
    "        Given an image tensor, passes it through U-Net and returns the output.\n",
    "        Parameters:\n",
    "            x: image tensor of shape (batch size, channels, height, width)\n",
    "        '''\n",
    "        x1 = self.contract1(x)\n",
    "        x2 = self.maxpool(x1)\n",
    "        x3 = self.contract2(x2)\n",
    "        x4 = self.maxpool(x3)\n",
    "        x5 = self.contract3(x4)\n",
    "        x6 = self.maxpool(x5)\n",
    "        x7 = self.contract4(x6)\n",
    "        x8 = self.expand1(x7)\n",
    "        x9 = self.expand2(x8)\n",
    "        x10 = self.expand3(x9)\n",
    "        xn = self.downfeature(x10)\n",
    "        #return self.sigmoid(xn)\n",
    "        return xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76bf7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# New parameters\n",
    "recon_criterion1 = nn.CosineEmbeddingLoss(0.5)\n",
    "recon_criterion2 = nn.MSELoss()\n",
    "lambda_recon1 = 1\n",
    "lambda_recon2 = 1\n",
    "\n",
    "n_epochs = 50\n",
    "input_dim = 17\n",
    "real_dim = 17\n",
    "display_step = 1000\n",
    "batch_size = 32\n",
    "lr = 0.002\n",
    "#target_shape = 100\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a636b",
   "metadata": {},
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745791cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data1, data2):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data1 = self.data1[index]\n",
    "        data2 = self.data2[index]\n",
    "        return data1, data2\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0735585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = UNet(input_dim, real_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.ConvTranspose1d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm1d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "gen = gen.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acce7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# GRADED CLASS: get_gen_loss\n",
    "def get_gen_loss(gen, real, condition, recon_criterion1, recon_criterion2, lambda_recon1, lambda_recon2):\n",
    "    '''\n",
    "    Return the loss of the generator given inputs.\n",
    "    Parameters:\n",
    "        gen: the generator; takes the condition and returns potential images\n",
    "        disc: the discriminator; takes images and the condition and\n",
    "          returns real/fake prediction matrices\n",
    "        real: the real images (e.g. maps) to be used to evaluate the reconstruction\n",
    "        condition: the source images (e.g. satellite imagery) which are used to produce the real images\n",
    "        adv_criterion: the adversarial loss function; takes the discriminator \n",
    "                  predictions and the true labels and returns a adversarial \n",
    "                  loss (which you aim to minimize)\n",
    "        recon_criterion: the reconstruction loss function; takes the generator \n",
    "                    outputs and the real images and returns a reconstructuion \n",
    "                    loss (which you aim to minimize)\n",
    "        lambda_recon: the degree to which the reconstruction loss should be weighted in the sum\n",
    "    '''\n",
    "    # Steps: 1) Generate the fake images, based on the conditions.\n",
    "    #        2) Evaluate the fake images and the condition with the discriminator.\n",
    "    #        3) Calculate the adversarial and reconstruction losses.\n",
    "    #        4) Add the two losses, weighting the reconstruction loss appropriately.\n",
    "    fake = gen(condition)\n",
    "    gen_rec_loss1 = recon_criterion1(real.flatten(start_dim=1).to(device), fake.flatten(start_dim=1).to(device), torch.ones(fake.shape[0]).to(device))\n",
    "    gen_rec_loss2 = recon_criterion2(real, fake)\n",
    "    gen_loss = lambda_recon1 * gen_rec_loss1 + lambda_recon2 * gen_rec_loss2\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935fa3b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69905f01a1e4d8ab1829430c594796e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 1: EEG2EEG loss: 1.946548801787356, Corr : 0.14550835927804814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62085f9ad5c84626afc05c87838217be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 2: EEG2EEG loss: 1.9068511813244922, Corr : 0.4433443932434831\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ecd9aabb3b48cf973ea4130cf93bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 3: EEG2EEG loss: 1.9016354616652145, Corr : 0.45181550673364956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894a1b304fa34bbbb288774856836185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 4: EEG2EEG loss: 1.8766460989383942, Corr : 0.48322211903515605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d9c6535b9b48a48b9a48fe2bb9e159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 5: EEG2EEG loss: 1.8717160947779392, Corr : 0.4799893994924209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d495d18247c949acb63628a4ae57f442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 6: EEG2EEG loss: 1.8782009190701423, Corr : 0.3406575960428128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f0b9e087474f1b8d47f3d251bac9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 7: EEG2EEG loss: 1.874485709565751, Corr : 0.456165411330217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be0e7a809f944ef8329abdb88153b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 8: EEG2EEG loss: 1.8611809801548085, Corr : 0.46305153644285163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cf274115df48fa807ad5099a2a21b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 9: EEG2EEG loss: 1.8675275749348579, Corr : 0.4455747421071027\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3750ea0e0afe442a97f78da4c3bd820b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 10: EEG2EEG loss: 1.8504713304499363, Corr : 0.48811771413430194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94245a24d4d4d5c959d48ed47f94fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 11: EEG2EEG loss: 1.84425036831105, Corr : 0.47095442589068903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593e88ffc19c4f8fadb7d9f0794163e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 12: EEG2EEG loss: 1.8410664530510599, Corr : 0.4937698167392714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e50f0ec759469c99dc95f1aeafd1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 13: EEG2EEG loss: 1.8350536214544417, Corr : 0.4970896810528234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6d66ba02ac43ffb0277487face8825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 14: EEG2EEG loss: 1.8354212971443826, Corr : 0.518492576410501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f836841fad4fd0a5a750fff58ae79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 15: EEG2EEG loss: 1.834880217592767, Corr : 0.4842965305214711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c305688b281b488bbf591efa6e05d0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 16: EEG2EEG loss: 1.8306815966646721, Corr : 0.5189546276482149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea9deb5ba4943cbb0389793d99b6c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 17: EEG2EEG loss: 1.8262744926391763, Corr : 0.541923510138602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140b0b249d9b498c8a1a797a0ebf3ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 18: EEG2EEG loss: 1.82152813546201, Corr : 0.5225691875078833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d5d2a1b88b44cdb5e6fbc049fc08a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 19: EEG2EEG loss: 1.8279415495852207, Corr : 0.5463757593967269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110f6414f81a44e18682e7fe9a503085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 20: EEG2EEG loss: 1.813977558562096, Corr : 0.5313661262423963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fa0efad03b43759892ac1ec1750be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 21: EEG2EEG loss: 1.823643425677685, Corr : 0.4885538456475329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd2600fabea45069891d3da22e29047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 22: EEG2EEG loss: 1.8236904068196074, Corr : 0.5461001042573294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6310a9fc671a40e9ad712e4a8bb83851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 23: EEG2EEG loss: 1.8166685687734725, Corr : 0.4582074990759273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c85f148d4740d39fe8101130aad32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 24: EEG2EEG loss: 1.8158998755698508, Corr : 0.5362506551389864\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f84acd9dcef49a4a769e77c1766024d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 25: EEG2EEG loss: 1.8136524139566625, Corr : 0.5276008922212965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29989f61afdd483788009f6d75a5988b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 26: EEG2EEG loss: 1.807682865477623, Corr : 0.5392213798742607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0a5647126d47cb9548b69189448e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 27: EEG2EEG loss: 1.8042487654280155, Corr : 0.5192625247065225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b482f5850041ee883f019bf088adf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 28: EEG2EEG loss: 1.811260756025923, Corr : 0.5510622551620397\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31f8415fe094d298b9f9bf2175eef82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 29: EEG2EEG loss: 1.8049840838351148, Corr : 0.5421882253305738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92db469a4e044f9e8d8b209bb66d036e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 30: EEG2EEG loss: 1.807293491160616, Corr : 0.5472291368836963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42e2d58249044e5a0aa072c87b27813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 31: EEG2EEG loss: 1.805653508673323, Corr : 0.5452969372470003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c46d543441436d91f0a2a329123d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 32: EEG2EEG loss: 1.8045536685497203, Corr : 0.5282440521306184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c2d8d038c94b47a4e93cf74726ba99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 33: EEG2EEG loss: 1.8070625345757667, Corr : 0.5095949349381871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb3a00458f944b7ba4e59dd2ca9d981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 34: EEG2EEG loss: 1.8111810760295137, Corr : 0.5432127470495238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b025dd96ed443cbf96e72fb5525173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 35: EEG2EEG loss: 1.803577353345587, Corr : 0.5419170713862904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75532cb9e4344e818a5582fbde1e5617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 36: EEG2EEG loss: 1.7980026234971715, Corr : 0.5519172142207677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c3ef6f4475433d87d07216a4c32355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 37: EEG2EEG loss: 1.8000884094136826, Corr : 0.5340238225663912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4e5b5153c84fcda928c030b352c493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 38: EEG2EEG loss: 1.799240823755873, Corr : 0.5545808629298455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4549eefa79744870bb5ac0e84709269d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 39: EEG2EEG loss: 1.8024154153275997, Corr : 0.550252644837494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fccb26a7024de3a91321ed7d56aff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 40: EEG2EEG loss: 1.8075141057055046, Corr : 0.5444928188101039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8fdd160c744b388fe32d4013c9c1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 41: EEG2EEG loss: 1.8060393206616665, Corr : 0.5471123285065512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310c4fdfd03f46e4983c63861c1ddfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 42: EEG2EEG loss: 1.8000907339948289, Corr : 0.5460508131114311\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31aa343386d43699af346f595ba6f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 43: EEG2EEG loss: 1.8006237402875374, Corr : 0.5447700051376335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66045cdc76b34341a898bd81f57341aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 44: EEG2EEG loss: 1.7935952709076253, Corr : 0.5395607187612057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2a0847da9e4cecb0b8f1b94de5b798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 45: EEG2EEG loss: 1.8004874739241092, Corr : 0.5369917386214762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc21164c29a4f149e8e442f8577f27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 46: EEG2EEG loss: 1.798470432453967, Corr : 0.5460984289357242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36af8c3df994ad5a65b95b8d2437f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 47: EEG2EEG loss: 1.7940595682631149, Corr : 0.5356289250358874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1e5ddab43b40b18cd44a50125a5629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 48: EEG2EEG loss: 1.7984790611774364, Corr : 0.5547861660076252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8854ed06864e497fb6d1717c71b00030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 49: EEG2EEG loss: 1.7883642328546403, Corr : 0.5496218063792793\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8284d13598c049c59273b4c2f7684f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 using 3000 trials, Sub01 -> Sub02: Epoch 50: EEG2EEG loss: 1.7896467586781115, Corr : 0.5443164402839503\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7482268f1ef843b7b9d79f47e32aa1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 1.14 GiB already allocated; 0 bytes free; 1.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 75>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m testsub2data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(testsub2data, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     95\u001b[0m testsub2data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(testsub2data)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 96\u001b[0m \u001b[43mtrain_and_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraindata1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraindata2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestsub1data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestsub2data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubid1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubid2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[1;34m(data1, data2, input_dim, real_dim, lr, testsub1data, testsub2data, subid1, subid2)\u001b[0m\n\u001b[0;32m     34\u001b[0m real \u001b[38;5;241m=\u001b[39m real\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     36\u001b[0m gen_opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 37\u001b[0m gen_loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_gen_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecon_criterion1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecon_criterion2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_recon1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_recon2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m gen_loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Update gradients\u001b[39;00m\n\u001b[0;32m     39\u001b[0m gen_opt\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Update optimizer\u001b[39;00m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mget_gen_loss\u001b[1;34m(gen, real, condition, recon_criterion1, recon_criterion2, lambda_recon1, lambda_recon2)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mReturn the loss of the generator given inputs.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    lambda_recon: the degree to which the reconstruction loss should be weighted in the sum\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Steps: 1) Generate the fake images, based on the conditions.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#        2) Evaluate the fake images and the condition with the discriminator.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#        3) Calculate the adversarial and reconstruction losses.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#        4) Add the two losses, weighting the reconstruction loss appropriately.\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m fake \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m gen_rec_loss1 \u001b[38;5;241m=\u001b[39m recon_criterion1(real\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device), fake\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mones(fake\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     26\u001b[0m gen_rec_loss2 \u001b[38;5;241m=\u001b[39m recon_criterion2(real, fake)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    191\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontract2(x2)\n\u001b[0;32m    192\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x3)\n\u001b[1;32m--> 193\u001b[0m x5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontract3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m x6 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x5)\n\u001b[0;32m    195\u001b[0m x7 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontract4(x6)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mContractingBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm(x)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dropout:\n\u001b[1;32m---> 51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[1;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 1.14 GiB already allocated; 0 bytes free; 1.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "def train_and_test(data1, data2, input_dim, real_dim, lr, testsub1data, testsub2data, subid1, subid2):\n",
    "    \n",
    "    for k in range(10):\n",
    "        \n",
    "        gen = UNet(input_dim, real_dim).to(device)\n",
    "        gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "        gen = gen.apply(weights_init)\n",
    "        \n",
    "        index = np.arange(16540)\n",
    "        np.random.shuffle(index)\n",
    "        \n",
    "        for i in range(5):\n",
    "    \n",
    "            epochs_loss = np.zeros([n_epochs])\n",
    "            epochs_corr = np.zeros([n_epochs])\n",
    "            \n",
    "            torch_data = GetData(torch.from_numpy(traindata1[index[:3000*(i+1)]]).float(), torch.from_numpy(traindata2[index[:3000*(i+1)]]).float())\n",
    "    \n",
    "            dataloader = DataLoader(torch_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            best_corr = 0\n",
    "    \n",
    "            gen.train()\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                loss = 0\n",
    "                # Dataloader returns the batches\n",
    "                cur_step = 0\n",
    "                for data1, data2 in tqdm(dataloader):\n",
    "                    condition = data1\n",
    "                    real = data2\n",
    "                    cur_batch_size = len(condition)\n",
    "                    condition = condition.to(device)\n",
    "                    real = real.to(device)\n",
    "\n",
    "                    gen_opt.zero_grad()\n",
    "                    gen_loss = get_gen_loss(gen, real, condition, recon_criterion1, recon_criterion2, lambda_recon1, lambda_recon2)\n",
    "                    gen_loss.backward() # Update gradients\n",
    "                    gen_opt.step() # Update optimizer\n",
    "                    loss += gen_loss.item()\n",
    "            \n",
    "                    cur_step += 1\n",
    "        \n",
    "                gen.eval()\n",
    "                gen_opt.zero_grad()\n",
    "        \n",
    "                testsub1data = testsub1data.to(device)\n",
    "                testsub2data = testsub2data.to(device)\n",
    "        \n",
    "                testsub2fakedata = gen(testsub1data)\n",
    "        \n",
    "                arr1 = testsub2fakedata.detach().cpu().numpy()\n",
    "                arr2 = testsub2data.detach().cpu().numpy()\n",
    "        \n",
    "                corr = spearmanr(arr1.flatten(), arr2.flatten())[0]\n",
    "            \n",
    "                # Keep track of the average generator loss\n",
    "                mean_loss = loss / cur_step\n",
    "        \n",
    "                print('Round ' + str(k+1) + ' using ' + str(3000*(i+1)) + ' trials, Sub' + str(subid1+1).zfill(2) + ' -> ' + 'Sub' + str(subid2+1).zfill(2) + ': ' + f\"Epoch {epoch+1}: EEG2EEG loss: {mean_loss}, Corr : {corr}\")\n",
    "                #show(condition, fake, real)\n",
    "                loss = 0\n",
    "                epochs_loss[epoch] = mean_loss\n",
    "                epochs_corr[epoch] = corr\n",
    "                if corr > best_corr:\n",
    "                    best_corr = corr\n",
    "                    best_gen = copy.deepcopy(gen.state_dict())\n",
    "                    best_gen_opt = copy.deepcopy(gen_opt.state_dict())\n",
    "            torch.save({'gen':  best_gen,\n",
    "                        'gen_opt': best_gen_opt\n",
    "                        }, f\"weights_steps/Sub{subid1+1}ToSub{subid2+1}_AllChannels/best_model_round{k+1}_{3000*(i+1)}trials.pth\")\n",
    "            np.save(f'weights_steps/Sub{subid1+1}ToSub{subid2+1}_AllChannels/gloss_round{k+1}_{3000*(i+1)}trials.npy', epochs_loss)\n",
    "            np.save(f'weights_steps/Sub{subid1+1}ToSub{subid2+1}_AllChannels/corr_round{k+1}_{3000*(i+1)}trials.npy', epochs_corr)\n",
    "\n",
    "for subid1 in range(10):\n",
    "    for subid2 in range(10):\n",
    "        if subid1 < subid2 and subid1 != 8 and subid2 != 8:\n",
    "            traindata1 = np.load('eeg_data/train/sub' + str(subid1+1).zfill(2) + '.npy')\n",
    "            mean1 = np.average(traindata1)\n",
    "            std1 = np.std(traindata1)\n",
    "            traindata1 = (traindata1-mean1)/std1\n",
    "            traindata1 = np.transpose(traindata1, (1, 0, 2))\n",
    "            traindata2 = np.load('eeg_data/train/sub' + str(subid2+1).zfill(2) + '.npy')\n",
    "            mean2 = np.average(traindata2)\n",
    "            std2 = np.std(traindata2)\n",
    "            traindata2 = (traindata2-mean2)/std2\n",
    "            traindata2 = np.transpose(traindata2, (1, 0, 2))\n",
    "            testsub1data = np.load('eeg_data/test/sub' + str(subid1+1).zfill(2) + '.npy')\n",
    "            testsub1data = (testsub1data-mean1)/std1\n",
    "            testsub1data = np.transpose(testsub1data, (1, 0, 2))\n",
    "            testsub1data = torch.from_numpy(testsub1data).float()\n",
    "            testsub2data = np.load('eeg_data/test/sub' + str(subid2+1).zfill(2) + '.npy')\n",
    "            testsub2data = (testsub2data-mean2)/std2\n",
    "            testsub2data = np.transpose(testsub2data, (1, 0, 2))\n",
    "            testsub2data = torch.from_numpy(testsub2data).float()\n",
    "            train_and_test(traindata1, traindata2, input_dim, real_dim, lr, testsub1data, testsub2data, subid1, subid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf5eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
